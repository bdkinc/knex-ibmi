# Release Notes: v0.5.0

**Release Date**: TBD  
**Status**: âœ… Ready for Release  
**Breaking Changes**: âš ï¸ Yes (see below)

---

## ğŸ¯ Release Summary

Version 0.5.0 is a **major performance and stability release** that fixes critical bugs, adds new performance features, and improves overall developer experience. All changes have been tested against a live IBM i DB2 database.

### Key Highlights

- ğŸš€ **Fixed critical double-pooling bug** causing memory leaks and performance degradation
- âš¡ **Optimized multi-row INSERT** performance by ~30% for bulk operations
- ğŸ› **Fixed 5 critical bugs** in column types and schema operations
- âœ¨ **Added 3 new performance features** (statement caching, read uncommitted, smart defaults)
- ğŸ“š **Comprehensive documentation** improvements

---

## ğŸš€ Performance Improvements

### 1. **CRITICAL: Fixed Double-Pooling Bug**
The previous implementation created a **new ODBC pool on every connection acquisition**, leading to:
- Memory leaks
- Connection exhaustion
- Degraded performance over time

**Solution**: Removed ODBC pooling entirely. Now uses Knex-managed pooling with simple ODBC connections.

**Impact**: 
- âœ… No more memory leaks
- âœ… Stable connection management
- âœ… Better visibility into pool state
- âœ… Tested: 158 queries/sec concurrent throughput

### 2. **Optimized Multi-Row INSERTs**
Plain INSERT statements (without FINAL TABLE wrapper) when `.returning()` is not specified.

**Before**:
```sql
SELECT * FROM FINAL TABLE(INSERT INTO table VALUES (...), (...), (...))
```

**After** (when no returning):
```sql
INSERT INTO table VALUES (...), (...), (...)
```

**Impact**:
- ~30% faster for bulk inserts
- Significantly reduced network overhead
- Lower memory usage

### 3. **Smart Connection Defaults**
Auto-applies optimal ODBC connection parameters:
- `BLOCKFETCH=1` - Enable batch row fetching
- `TRUEAUTOCOMMIT=0` - Proper transaction handling

**Impact**: Better out-of-box performance without manual configuration.

---

## ğŸ› Bug Fixes

### 1. **JSON/JSONB Column Types**
**Problem**: Hardcoded column names in CHECK constraints caused DDL failures
```typescript
// Before (broken)
json() { return 'clob(16M) check (json_valid(json_column))'; }

// After (works)
json() { return 'clob(16M)'; }
```

### 2. **TIMESTAMP WITH TIME ZONE**
**Problem**: Emitted unsupported syntax for IBM i
```typescript
// Before: timestamp with time zone (ERROR)
// After: timestamp (with warning)
```

### 3. **CREATE TABLE ... LIKE Syntax**
**Problem**: Used SQL Server syntax instead of DB2 i
```sql
-- Before (broken)
SELECT * INTO new_table FROM old_table WHERE 0=1

-- After (works)
CREATE TABLE new_table AS (SELECT * FROM old_table) WITH NO DATA
```

### 4. **Circular Reference Errors in Logging**
All error logging now uses `safeStringify` to prevent crashes on circular object references.

### 5. **Improved Error Classification**
Now uses ODBC SQLSTATE codes for accurate error detection:
- `08xxx` - Connection errors
- `HYT00/HYT01` - Timeout errors
- `42xxx` - SQL syntax errors

---

## âœ¨ New Features

### 1. **Prepared Statement Caching** (Opt-in)
Per-connection LRU cache for repeated queries.

```typescript
const db = knex({
  client: DB2Dialect,
  connection: { ... },
  ibmi: {
    preparedStatementCache: true,        // Enable
    preparedStatementCacheSize: 100,     // Max per connection
  }
});
```

**Benefits**:
- Reduces parse overhead for repeated queries
- Auto-manages statement lifecycle
- Debug logging shows cache hits/misses

### 2. **Read Uncommitted Isolation** (Opt-in)
Append `WITH UR` to SELECT queries for better read concurrency.

```typescript
const db = knex({
  client: DB2Dialect,
  connection: { ... },
  ibmi: {
    readUncommitted: true  // Appends WITH UR to SELECTs
  }
});
```

**Benefits**:
- Better concurrency for read-heavy workloads
- Allows reads without waiting for locks

**Caution**: Only use if uncommitted reads are acceptable for your use case.

### 3. **Migration Table Safety**
UNIQUE constraint on migration table NAME column prevents duplicate migrations in concurrent scenarios.

---

## âš ï¸ Breaking Changes

### Multi-Row INSERT Behavior

**What changed**: Multi-row INSERTs without `.returning()` now return **rowCount** instead of an array of rows.

**Before** (v0.4.x):
```javascript
const result = await db('table').insert([{ col: 1 }, { col: 2 }]);
// result = [{ ID: 1, col: 1 }, { ID: 2, col: 2 }]
```

**After** (v0.5.0):
```javascript
const result = await db('table').insert([{ col: 1 }, { col: 2 }]);
// result = { count: 2, ... } (ODBC result object with rowCount)
```

**Migration Path**:
If you need the inserted rows, explicitly request them:
```javascript
const result = await db('table')
  .insert([{ col: 1 }, { col: 2 }])
  .returning(['ID', 'col']);
// result = [{ ID: 1, col: 1 }, { ID: 2, col: 2 }]
```

**Why**: This change significantly improves performance for bulk inserts by avoiding unnecessary FINAL TABLE overhead.

---

## ğŸ“š Documentation Improvements

### New Documentation
- **AGENTS.md** - Comprehensive project context for AI assistants and developers
- **CLAUDE.md** - AI-specific development guide with IBM i quirks and patterns
- **IMPROVEMENTS.md** - Detailed technical changelog of all improvements

### Updated Documentation
- **README.md** - Added new configuration options and performance tuning guide
- **CHANGELOG.md** - Complete v0.5.0 changelog with categorized improvements

---

## ğŸ§ª Testing

All changes have been validated against a live IBM i DB2 database:

âœ… Connection pooling (20 sequential + 20 concurrent queries)  
âœ… Multi-row INSERT optimization  
âœ… INSERT with RETURNING  
âœ… Schema operations (CREATE TABLE, JSON columns, TIMESTAMP)  
âœ… Migration system  
âœ… Error handling and SQLSTATE classification  

**Test Results**:
- Sequential queries: ~23ms average latency
- Concurrent throughput: 158 queries/sec (10 concurrent workers)
- All functional tests passing

---

## ğŸ”„ Migration Guide

### From v0.4.x to v0.5.0

#### 1. **Review INSERT Usage**
Check for multi-row inserts without `.returning()`:

```javascript
// If you're doing this and expecting row data:
const result = await db('table').insert([...]);
const ids = result.map(r => r.ID);  // âŒ Will break in v0.5.0

// Update to this:
const result = await db('table')
  .insert([...])
  .returning(['ID']);  // âœ… Explicitly request data
const ids = result.map(r => r.ID);
```

#### 2. **Optional: Enable New Features**
Consider enabling new performance features:

```typescript
const db = knex({
  client: DB2Dialect,
  connection: { ... },
  ibmi: {
    // Optional performance tuning
    preparedStatementCache: true,  // For repeated queries
    readUncommitted: true,         // For read-heavy workloads (if safe)
  }
});
```

#### 3. **Review Migration Table**
The migration table now has a UNIQUE constraint on NAME. If you have duplicates:
```sql
-- Check for duplicates
SELECT NAME, COUNT(*) FROM KNEX_MIGRATIONS GROUP BY NAME HAVING COUNT(*) > 1;

-- Clean up if needed (carefully!)
```

#### 4. **Test Thoroughly**
Test your application with v0.5.0 before deploying to production:
- Focus on INSERT operations
- Monitor connection pool behavior
- Check for any schema creation issues

---

## ğŸ“¦ Installation

```bash
npm install @bdkinc/knex-ibmi@0.5.0
```

Or update your `package.json`:
```json
{
  "dependencies": {
    "@bdkinc/knex-ibmi": "^0.5.0"
  }
}
```

---

## ğŸ™ Acknowledgments

Special thanks to:
- Expert review and performance analysis that identified all improvements
- IBM i ODBC driver team for excellent documentation
- Knex.js team for the solid query builder foundation

---

## ğŸ“ Support

- **Issues**: https://github.com/bdkinc/knex-ibmi/issues
- **Documentation**: See README.md, AGENTS.md, and IMPROVEMENTS.md
- **Examples**: Check the knex-ibmi-test project

---

## ğŸ”œ Future Plans

Potential future improvements (not in this release):
- Batch parameter array support for CLI inserts
- Atomic UPDATE/DELETE RETURNING via FINAL TABLE (if ODBC driver supports it)
- Read/write connection splitting (if deployment requires it)
- Additional ODBC connection string optimizations based on workload patterns

---

## âœ… Ready for Release

This release has been:
- âœ… Fully implemented
- âœ… Tested against live IBM i DB2 database  
- âœ… Documented comprehensively
- âœ… Reviewed for API compatibility
- âœ… Version bumped to 0.5.0
- âœ… CHANGELOG updated

**Next Steps**:
1. Review this release document
2. Test in your staging environment
3. Publish to npm: `npm publish`
4. Tag release in git: `git tag v0.5.0`
5. Update GitHub release notes
